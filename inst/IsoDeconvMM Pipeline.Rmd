---
title: "IsoDeconvMM Pipeline"
author: "Hillary Heiling"
date: "October 16, 2019"
output: html_document
---

## Items needed before Step 0:

* .bam files of mixture and pure samples (not .bai)
* Cuffdiff output

## Original Process: Before GeneModel_Build.R file and corresponding processes

*Step 0.1*: step1_check_and_filter.R

Input: .bam files - mixed and pure sample files

[[Note: In real data case, both mixed and pure samples. In the simulated case when the mixed samples are derivatives of the pure samples, only need to run process on pure samples, then create mixtures based on the pure sample output (see below). Reference: FragLengths_Function_mixture.R]]

Note: Need "_counts.txt" files for both mixture and pure samples in Step 1, which are created in Step 0.3. Seems need to run this process on both mixture and pure samples.

Output: "_sorted_by_name_uniq_filterd.bam" files (_count/ folder in Doug's code)

*Step 0.2*: step2_read_depth.R

Diagnostics only. Optional?

Input: "count_ ... .txt" files from Step 0.1

Output: Summary plot (pdf)

*Step 0.3*: step3_countReads.R

Inputs: .bed file, all "_sorted_by_name_unique_filtered.bam" files from Step 0.1

Output: "_counts.txt" file from countReads() function from `isoform` library

*Step 0.4*: step4_summarize_counts.r

Inputs: 

* Some .RData object (Homo_sapiens.GRCh37.66.nTE.RData, or its equivalent)
* The "_counts.txt" files from step 0.3

Output: A dataset with the gene counts matrix with file name "gene_counts_%d_%d.txt"

Note: I haven't seen where the gene_counts_..._.txt files are used.

*Step 0.5*: FragLengths_Function_mixutre.R

Inputs: Mixture .bam files (in the non-simulated process, also of type "_sorted_by_name_unique_filtered.bam"), pure sample reference "_sorted_by_name_unique_filtered.bam" files from Step 0.1.

Process: Create combinations of files where there is one mixture file and all cell reference files, then run the fragSizeFile process (see isoform vignette) on this file combination.

Wei Sun: "Basically, it combines samtools command and unix command awk to evaluate the fragment length. Say you have a paired end read and you know what the two ends are mapped. Then you can find how long is the whole fragment."

Outputs: fragSizeFile with suffix "_fraglens.txt" for the one mixture + all reference files combinations.

Note: Will need to run code in R in the command line

## Updated Process: Step 0

Step 0.1:

Thoughts: Need to run in command line (source the R file)

```{r}
library(asSeq)

intputDir = "where/.bam/files/are"
outputFolder = "IsoDeconvMM_Materials/" # Originally, _count/ folder for Doug
#------------------------------------------------------------------
# Generating BAM file List            
#------------------------------------------------------------------

#Set working directory to folder where BAM files are located:
setwd(inputDir)

#Generate initial list of files: (NOTE- .bam.bai files included)
init_list = list.files(pattern=".bam")

#Generate list of .bai files
int_list = list.files(pattern=".bai")

#Final List (excluding .bai files):
BAM_list = setdiff(init_list,int_list)

# -----------------------------------------------------------------
# check the bam files
# -----------------------------------------------------------------

#Checks length of BAM files to ensure all has run properly:
length(BAM_list)

#Displays BAM list as another check for errors:
BAM_list

bam2use = BAM_list

#Loop across all BAM files in the folder:
for(i in 1:length(BAM_list)){

  bami = bam2use[i]
  
  #Generates a name that can be used in the files by stripping 
  #off the .BAM extension:
  sami = substr(bam2use[i],start=1,stop=nchar(bam2use[i])-4)
  
  # ----------------------------------------------------------
  # counting
  # ----------------------------------------------------------
  ctF  = sprintf("%s/count_%s.txt", outputFolder,sami)
  cmd1 = sprintf("samtools view %s | wc -l >> %s\n", bam2use[i], ctF)
  system(cmd1)
  
  # ----------------------------------------------------------
  # sorting
  # ----------------------------------------------------------
  cmd2 = sprintf("samtools sort -n %s %s/%s_sorted_by_name", bam2use[i], outputFolder, sami)
  system(cmd2)
  bamF = sprintf("%s/%s_sorted_by_name.bam", outputFolder, sami)
  
  # ----------------------------------------------------------
  # getUnique and filtering
  # ----------------------------------------------------------
  prepareBAM(bamF, sprintf("%s/%s_sorted_by_name", outputFolder, sami), sortIt=FALSE)
  
  system(sprintf("rm %s", bamF))
  
  # ----------------------------------------------------------
  # counting again
  # ----------------------------------------------------------
  cmd3   = sprintf("samtools view %s/%s_sorted_by_name_uniq_filtered.bam | wc -l >> %s\n", outputFolder, sami, ctF)
  system(cmd3)
}

```

Step 0.2: Diagnostics only (?)

Step 0.3:

Note: Run in command line (source the R code)

```{r}

#--------------------------------------------------------------------------------------
# Set Parameters
#--------------------------------------------------------------------------------------

# Input directory: has the "sorted_by_name_uniq_filtered.bam" files
inputDir = "IsoDeconvMM_Materials/" # Output folder from Step 0.1
# BED file (once identified and downloaded)
bedFile = "/netscr/drwilson/Reference_Annotations/Homo_sapiens/Homo_sapiens.GRCh37.66.nonoverlap.exon.bed"

#--------------------------------------------------------------------------------------
# ISOFORM Software Library Access
#--------------------------------------------------------------------------------------
library(isoform) 

#------------------------------------------------------------------------------------------------
# Set Working Directory
#------------------------------------------------------------------------------------------------
setwd(inputDir)

#------------------------------------------------------------------------------------------------
# Loop across all replicates and files:
#        For loop assumes that all files within a class (ECC1, HMEC, GM12878) have same bed File.
#------------------------------------------------------------------------------------------------

cmd  = "ls *_sorted_by_name_uniq_filtered.bam"
ffs  = system(cmd, intern=TRUE)
length(ffs)
head(ffs)
sams = gsub("_sorted_by_name_uniq_filtered.bam", "", ffs)

for(i in 1:length(ffs)){

  sam1 = sams[i]
  cat(i, sam1, date(), "\n")
  
  bamFile = ffs[i]
  outFile = sprintf("%s_counts.txt", sam1)
  
  countReads(bamFile, bedFile, outFile)
}
```

Step 0.4:

```{r}

#---------------------------------------------------------------------------------
# Set Parameters
#---------------------------------------------------------------------------------

# inputDir = same input directory from step 3 
gene_list = "/netscr/drwilson/Homo_sapiens.GRCh37.66.nTE.RData"

#---------------------------------------------------------------------------------
# Set Working Directory [EDIT]
#---------------------------------------------------------------------------------

setwd(inputDir)

#---------------------------------------------------------------------------------
# Load/Organize Gene List into Matrix Form
#---------------------------------------------------------------------------------

load(gene_list)
dim(nTE)
nTE[1:2,]
length(unique(nTE$geneId))

# Lists all count files in the current directory. Assigns number of such files
# to the idx2 random variable. To be used in looping.

ffs  = list.files(pattern="_counts.txt")
nn   = length(ffs)
ffs[1:2]
nn
idx2<-nn

# Creates matrix of following form:
#  -> One geneID per row
#  -> One Cell Line Sample per column
#  -> Count for gene i in sample j is cell value

# Labels rows by GeneID, labels columns (samples) by file name.

sams  = gsub("_counts.txt", "", ffs)
couts = matrix(0, nrow=nrow(nTE), ncol=(idx2-1+1))
colnames(couts) = sams[1:idx2]
rownames(couts) = nTE$geneId

#---------------------------------------------------------------------------------
# READ IN SAMPLE DATA:
#
# Reads in output from step 3 (countReads) and organizes it into a matrix form.
# Column 1: Read Count
# Column 2: Reference site (Transcript Cluster, Gene ID, Exons involved) 
#---------------------------------------------------------------------------------

for(idx in 1:idx2){
  
  cat(idx, date(), "\n")
  
  f1   = ffs[idx]
  dat  = scan(f1, what=character(0))  
  dat  = matrix(dat, ncol=2, byrow=TRUE);
 
  colNames = c("count", "exons")
  cN = sprintf("%s and %s", colNames[1], colNames[2])
 
# Error Checking: if a row does not have two columns, the procedure
# halts and warns the user.

  if(ncol(dat) != 2){
    stop(countFile, " should have 2 columns: ", cN, "\n")
  }
  
  colnames(dat) = colNames
  dim(dat)
  dat[1:2,]
  
#---------------------------------------------------------------------------------
# OBTAIN TRANSCRIPT CLUSTERS AND GENE IDS
#---------------------------------------------------------------------------------
  
# Splits each string from column 2 (reference sites) of the dat matrix into 3
# components: (i) Transcript cluster, (ii) Ensembl Gene ID, (iii) Exon Cluster.
# Output is a list of exon sets, one list for each line of original dat matrix.

  groupIDs = strsplit(dat[,"exons"], split=";|\\|", perl=TRUE)
  
# Creates function that will be used to extract the UNIQUE gene IDs from within
# each exon set.

  splitFun <- function(vx){
    unique(vx[grep("ENSG", vx)])
  }
  
#Extract unique geneIDs for each exon set read count.

  date()
  geneIDs = lapply(groupIDs, splitFun)
  date()
  geneIDs[1:2]
  
#---------------------------------------------------------------------------------
# DATA CHECKING:
#     This section assesses the number of unique gene IDs present for each exon 
# set/read count. If more than one unique geneID is present for an exon set,
# its reads are excluded. If only one geneID is present, these reads are assigned
# to that gene.
#---------------------------------------------------------------------------------
 
  ngIDs   = sapply(geneIDs, length)
  table(ngIDs)
  
  w2check = which(ngIDs > 1)
  
  chkGIDs <- function(g1){
    gkp    = ""
    ncombo = sum(!grepl(":", g1, fixed=TRUE))
    
    if(ncombo <= 1){
      g2s = strsplit(g1, split=":", fixed=TRUE)
      gus = unique(unlist(g2s))
      foundONE = FALSE
      
      for(gu1 in gus){
        if (all(grepl(gu1, g1))){
          if(foundONE){  
            gkp = ""
            break
          }else{
            foundONE = TRUE
            gkp = gu1
          }
        }
      }
    }
    
    gkp
  }

  gIDchk  = sapply(geneIDs[w2check], chkGIDs)
  length(gIDchk)
  gIDchk[1:4]
  
  geneIDs[w2check] = gIDchk
  n1      = length(geneIDs)
  geneIDs = unlist(geneIDs)
  if(n1 != length(geneIDs)){ stop("non-unique geneIDs\n") }
  
  gID2rm = w2check[which(gIDchk=="")]
  str1   = "combinations are skipped because they belong to different genes"
  message(length(gID2rm), " exon ", str1)
  
  dim(dat)
  if(length(gID2rm) > 0){
    dat     = dat[-gID2rm,]
    geneIDs = geneIDs[-gID2rm]
  }
  
  dim(dat)
  length(unique(geneIDs))
  
#---------------------------------------------------------------------------------
# RECORDING COUNTS:
#---------------------------------------------------------------------------------
 
# Converts counts from data matrix from character to numeric. Sums across all
# exon sets with the same, unique (after previous step), geneID.

  cts     = as.numeric(dat[,"count"])
  geneCts = tapply(cts, geneIDs, sum)
 
# Matches geneIDs from the geneCts matrix above with the nTE data set geneIDs
# for proper almagamation.
 
  mat1    = match(names(geneCts), nTE$geneId)
  wNotNA  = which(! is.na(mat1))
 
# Provides information on the number of geneIDs skipped during the process
# due to: (i) having two geneIDs present in read. 

  pp1 = round(sum(geneCts[-wNotNA])/sum(geneCts),4)
  nn1 = length(geneCts) - length(wNotNA)
  message(100*pp1, "% of reads @ ", nn1, " exon combinations are skipped\n")

# Updates original countmatrix with counts from the current sample passed through
# the for loop.

  couts[mat1[wNotNA],idx-1+1] = geneCts[wNotNA]
}

# Outputs a dataset with the gene counts matrix.

outF = sprintf("gene_counts_%d_%d.txt", 1, idx2)

write.table(couts, file = outF, append = FALSE, quote = FALSE, sep = "\t",
row.names = TRUE, col.names = TRUE)



```

Step 0.5 

```{r}
#-------------------------------------------------------------#
# Fragment Length Files: Generation                           #
#-------------------------------------------------------------#

#-------------------------------------------------------------#
# Set Parameters
#-------------------------------------------------------------#

# Specify Directory where read files are kept:
# inputDir same input directory as step 0.3 (output directory of step 0.1)
setwd(inputDir)

# BAM Files where sequenced reads are located:
inputFiles = c("./Mixtures/merged/mf_CD4_0_CD8_100.bam",
               "./Mixtures/merged/mf_CD4_10_CD8_90.bam",
               "./Mixtures/merged/mf_CD4_20_CD8_80.bam",
               "./Mixtures/merged/mf_CD4_30_CD8_70.bam",
               "./Mixtures/merged/mf_CD4_40_CD8_60.bam",
               "./Mixtures/merged/mf_CD4_50_CD8_50.bam",
               "./Mixtures/merged/mf_CD4_60_CD8_40.bam",
               "./Mixtures/merged/mf_CD4_70_CD8_30.bam",
               "./Mixtures/merged/mf_CD4_80_CD8_20.bam",
               "./Mixtures/merged/mf_CD4_90_CD8_10.bam",
               "./Mixtures/merged/mf_CD4_100_CD8_0.bam",
               "./CD4/_count/SRR1550995_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD4/_count/SRR1551016_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD4/_count/SRR1551098_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD8/_count/SRR1551024_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD8/_count/SRR1551051_SBC_sorted_by_name_uniq_filtered.bam",
               "./CD8/_count/SRR1551065_SBC_sorted_by_name_uniq_filtered.bam")

# Associated Labels for output files:
outputLabels = c("cd4_0_cd8_100",
                 "cd4_10_cd8_90",
                 "cd4_20_cd8_80",
                 "cd4_30_cd8_70",
                 "cd4_40_cd8_60",
                 "cd4_50_cd8_50",
                 "cd4_60_cd8_40",
                 "cd4_70_cd8_30",
                 "cd4_80_cd8_20",
                 "cd4_90_cd8_10",
                 "cd4_100_cd8_0",
                 "cd4_r1",
                 "cd4_r2",
                 "cd4_r3",
                 "cd8_r1",
                 "cd8_r2",
                 "cd8_r3")

# If any files are to be combined, list them in separate units:
comboList = list()
comboList[[1]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_0_cd8_100_lengths.txt")
comboList[[2]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_10_cd8_90_lengths.txt")
comboList[[3]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_20_cd8_80_lengths.txt")
comboList[[4]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_30_cd8_70_lengths.txt")
comboList[[5]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_40_cd8_60_lengths.txt")
comboList[[6]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_50_cd8_50_lengths.txt")
comboList[[7]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_60_cd8_40_lengths.txt")
comboList[[8]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_70_cd8_30_lengths.txt")
comboList[[9]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_80_cd8_20_lengths.txt")
comboList[[10]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_90_cd8_10_lengths.txt")
comboList[[11]] = c("cd4_r1_lengths.txt","cd4_r2_lengths.txt","cd4_r3_lengths.txt",
                   "cd8_r1_lengths.txt","cd8_r2_lengths.txt","cd8_r3_lengths.txt",
                   "cd4_100_cd8_0_lengths.txt")

# Combo Output Labels:
comboLabels = c("cd4_0_cd8_100",
                 "cd4_10_cd8_90",
                 "cd4_20_cd8_80",
                 "cd4_30_cd8_70",
                 "cd4_40_cd8_60",
                 "cd4_50_cd8_50",
                 "cd4_60_cd8_40",
                 "cd4_70_cd8_30",
                 "cd4_80_cd8_20",
                 "cd4_90_cd8_10",
                 "cd4_100_cd8_0")


fragLengths<-function(Input_Files,outputLabels,comboList,comboLabels,useCombo){
  outLabels = paste(outputLabels,"_lengths.txt",sep="")
  for(i in 1: length(Input_Files)){
    cmd1 = sprintf("samtools view -f 65 %s | awk '{print ($8>=$4) ? $8-$4+51 : $4-$8+51}' > %s",inputFiles[i],outLabels[i])
    system(cmd1)
  }
  
  if(missing(comboList) && useCombo==0){
    for(j in 1:length(outLabels)){
      cmd2_a = sprintf("cat %s | sort -n | uniq -c > %s_fraglens.txt",outLabels[j],outputLabels[j])
      system(cmd2_a)
    }
  } else if(useCombo==1 && missing(comboList)){
    stop("If you wish to combine files, you must list which files are to be combined!")
    
  } else { # comboList specified, and useCombo = 1
    
    ftc = unlist(lapply(X = comboList,FUN = function(x) {return(paste(x,collapse=" "))}))
    
    for(k in 1:length(comboList)){
      cmd2_b = sprintf("cat %s | sort -n | uniq -c > %s_fraglens.txt",ftc[k],comboLabels[k])
      system(cmd2_b)
    }
    
  }
}

fragLengths(Input_Files = inputFiles, outputLabels=outputLabels, comboList = comboList,
            comboLabels=comboLabels, useCombo=1)
```

## Original Process: GeneModel_Build and later

Note: Need to repeat process for each mixture file. These steps describe process for one mixture file (and all pure files).

*Step 1*:  Mixture_Creation / GeneModel_Build.R 

Calls dev_compiles_geneMod() function from isoDeconv_geneModel_revised.R file

Inputs: 

* countData = Vector of "_counts.txt" files from Step 0.3 (mixture and pure counts). One mixture file, all pure sample reference files
* labels = c("mix", "pure1_ref1", ..., "pure1_refp1", ..., "purek_refpk")
* total_cts = Vector of the total read count (in millions) for each RNA-seq read file. One element for each file. Can probably get from summing up all counts in each countData object
* cellTypes = c("mix", rep("pure1", times = p1), ..., rep("purek", times = pk))
* fragSizeFile = "_fraglens.txt" result from FragLenths_Function_mixture.R file (Step 0.5)
* bedFile = BED file
* knownIsoforms =
* readLen = read length, e.g. 75 bp or 100 pb. Get from sequencing data
* lmax = maximum fragment length
* eLenMin = 1

Output: fit_geneMod object

Note: Changed output of dev_compiles_geneMod() to be just an object, don't save an .RData object to some folder

*Step 2*:  Mixture_Creation / Restricting_Geneids_Pairwise.R

Establishes transcript clusters with highest levels of discriminatory capability

Library needed: biocLite.R library cummerbund

Inputs: "list_of_genes.txt" name annotation file, Cuffdiff_Out folder

Output: finalOut2 object as EnsembleIds2Use.RData object

*Step 3*:  Process_Real_Data / prepare_sigred.R

Inputs:  fin_geneMod object from *Step 1*, finalOut2 (EnsembleIds2Use.RData) object from *Step 2*

Output: sig_geneMod

*Step 4*:  Mixture_Creation / RecharacterizedOutput.R

Input: The sig_geneMod object from Step 3

Output:  Slightly modified version of sig_geneMod object

*Step 5*: Run pure sample production functions

Input: The modified sig_geneMod object from Step 4

Ouput: tmp.data = output from Pure.apply.fun() function from pure sample production functions file.

## Updated Process: GeneModel_Build.R and later

Step 1:

Note: need to generalize to multiple files (multiple combinations of one mixture and all cell type references). Perhaps run a loop for all mixture files

```{r}
# Required Libraries:
library(gtools)
library(IsoDeconvMM)

# Inputs
file = "g10h90" # Should be one of the comboLabels provided in FragLengths_Function_mixture.R

sys_statement1 = sprintf("countData=c(\"mf_%s_counts.txt\",
                         \"CD4_SRR1550995_SBC_counts.txt\",
                         \"CD4_SRR1551016_SBC_counts.txt\",
                         \"CD4_SRR1551098_SBC_counts.txt\",
                         \"CD8_SRR1551024_SBC_counts.txt\",
                         \"CD8_SRR1551051_SBC_counts.txt\",
                         \"CD8_SRR1551065_SBC_counts.txt\")",file)
eval(parse(text=sys_statement1))
labels = c("mix","CD4_ref1","CD4_ref2","CD4_ref3",
           "CD8_ref1","CD8_ref2","CD8_ref3")
cellTypes = c("mix","CD4","CD4","CD4",
              "CD8","CD8","CD8")
fragSizeFile = sprintf("/netscr/drwilson/2018-04-05 Paper 1/Frag_Lengths/%s_fraglens.txt",file)
bedFile = "/netscr/drwilson/Reference_Annotations/Homo_sapiens/Homo_sapiens.GRCh37.66.nonoverlap.exon.bed"
knownIsoforms = "/netscr/drwilson/Reference_Annotations/Homo_sapiens/Homo_sapiens.GRCh37.66.nonoverlap.exon.knownIsoforms.RData"
readLen=50
lmax=600
eLenMin=1

```

Suppose the above process has been generalized to multiple files

```{r}
files = file

final_geneMod = list()

for(j in 1:length(files)){
  # Call dev_compiled_geneMod function
  fin_geneMod = dev_compiled_geneMod(countData=countData,labels = labels,total_cts = total_cts, 
                       cellTypes=cellTypes, bedFile=bedFile,knownIsoforms=knownIsoforms,
                       fragSizeFile=fragSizeFile,output=output,readLen=readLen,lmax=lmax,
                       eLenMin=eLenMin)
  final_geneMod[[j]] = fin_geneMod
}

```


Step 2:

```{r}
#-----------------------------------------------------------------------------#
# ESTABLISHING CLUSTERS WITH HIGHEST LEVELS OF DISCRIMINATORY CAPABILITY      #
#-----------------------------------------------------------------------------#

#------------------ LOAD AND PROCESS GENE NAMES -------------------#
anno_names = read.table(file = "D:/DougData/Documents/Genomics Training Grant/Update_12_10_2014/FINAL/Article/list_of_genes.txt",header = TRUE,sep = ",")
anno_names$gene_short_name = anno_names$Associated.Gene.Name

#------------------ CALL THE LIBRARY ------------------#
source("https://bioconductor.org/biocLite.R")
biocLite("cummeRbund")
library(cummeRbund)

# Had to downgrade to RSQ-lite v 1.1-2

#------------------ Identify Highly Discriminatory Clusters -------------------#

# Run Cuffdiff, then point to the location of the Cuffdiff output folder and the name of the folder

finalOut2 = EnsemblIds2Use(folder = "Cuffdiff_Out",
                            directory = "D:/DougData/Documents/Dissertation/Paper 1 - Cell Type Abundance Estimation/Daily Work/1_30_2018/")

```

Step 3:

```{r}

analy_genes = finalOut2$Ensembl.ID

significant_geneMod = list()

for(j in 1:length(final_geneMod)){

  fin_geneMod = final_geneMod[[j]]
  
  indices2chk = which(names(fin_geneMod)!="Sample_Info")
  indices_tmp = NULL
  indices=NULL
  # indices_tmp = rep(0,length(geneMod)) # What is this geneMod object?
  # Idea: should be fin_geneMod instead of geneMod
  indices_tmp = rep(0,length(fin_geneMod))
  for(i in indices2chk){
    infodf = fin_geneMod[[i]]$info
    genesi = unique(infodf$gene)
    genesi = unique(unlist(strsplit(x=genesi,split = ":")))
    if(any(genesi %in% analy_genes)){indices_tmp[i]=1}
  }
  indices = which(indices_tmp==1)
  
  sig_geneMod = fin_geneMod[indices]
  sig_geneMod["Sample_Info"] = fin_geneMod["Sample_Info"]
  
  sig_geneMod = rem_clust(geneMod = sig_geneMod,co = 5,min_ind = 0)
  
  significant_geneMod[[j]] = sig_geneMod
}
```

Step 4:

```{r}

library(gtools)

#-------------------------------------------------------------------#
# EDIT TO GROUP CELL TYPES                                          #
#-------------------------------------------------------------------#

modified_sig_geneMod = list()

for(f in 1:length(significant_geneMod)){
  
  sig_geneMod = significant_geneMod[[f]]
  
  info_mat = sig_geneMod[["Sample_Info"]]
  cellTypes = unique(info_mat$Cell_Type)
  
  ctList = list()
  
  for(j in 1:length(cellTypes)){
    idx = which(info_mat$Cell_Type==cellTypes[j])
    ctList[[cellTypes[j]]] = list(samps = info_mat$Label[idx], tots = info_mat$Total[idx])
  }
  
  idx2consider = which(names(sig_geneMod)!="Sample_Info")
  for(k in idx2consider){
    for(l in 1:length(cellTypes)){
      samps2use = ctList[[l]]$samps
      tots      = ctList[[l]]$tots
  
      y_vecs  = paste("sig_geneMod[[k]]$y",samps2use,sep = "_")
      y_vecsc = paste(y_vecs,collapse = ",")
      nExon = eval(parse(text=sprintf("length(%s)",y_vecs[1])))
      textcmd = sprintf("matrix(c(%s),nrow=nExon,ncol=length(samps2use))",y_vecsc)
      expMat  = eval(parse(text=textcmd))
  
      totmg   = tots-colSums(expMat)
      expMat2 = rbind(totmg,expMat)
  
      if(cellTypes[l]!="mix"){
        sig_geneMod[[k]][[cellTypes[l]]] = list(cellType=cellTypes[l],rds_exons=expMat2)
      } else {
        sig_geneMod[[k]][[cellTypes[l]]] = list(cellType=cellTypes[l],rds_exons_t=expMat2)
      }
      
    }
  }
  
  modified_sig_geneMod[[f]] = sig_geneMod
  
}

```

Step 5:

Note: Confused about what files are used here

```{r}
# Call_Model / Revised_Sim_PS_codeNew.R code process

library(gtools)
library(alabama)

#-----------------------------------------------------------#
# CALL Pure Sample                                          #
#-----------------------------------------------------------#
cellTypes = c("cd4","cd8")

pure_est = list()

for(j in 1:length(modified_sig_geneMod)){
  
  sig_geneMod = modified_sig_geneMod[[j]]
  
  sim.out = sig_geneMod[which(names(sig_geneMod)!="Sample_Info")]

  # Clusters with single isoforms:
  # EXCLUDE THEM FOR THE MOMENT!.
  dim_mat = matrix(0,nrow=length(sim.out),ncol=2)
  excl_clust = c()
  excl_clust2 = c()
  for(i in 1:length(sim.out)){
    dim_mat[i,] = dim(sim.out[[i]][["X"]])
    if(all(dim_mat[i,]==c(1,1))){
      excl_clust = c(excl_clust,i)
    }
    if(dim_mat[i,2] == 1){
      excl_clust2 = c(excl_clust2,i)
    }
  }
  
  excl_clust_union = union(excl_clust,excl_clust2)
  if(length(excl_clust_union)>0){
    sim.new = sim.out[-c(excl_clust_union)]
  } else {
    sim.new = sim.out
  }
  
  
  # Optimize the Pure Sample Functions:
  tmp.data = Pure.apply.fun(data.list = sim.new, cellTypes = cellTypes, corr_co = 1)
  
  pure_est[[j]] = tmp.data
    
}



```

Step 6:

Multiple Cluster code: (Revised_Sim_Mix_Calls_MI.R)

Calls Single Cluster code: (Revised_Sim_MixCode_SI.R)

```{r}

library(alabama)

IsoDeconv_Output = list()

for(i in 1:length(pure_est)){
  
  tmp.data = pure_est[[i]]
  
  #--------------------------------------------------------#
  # Establish input break ups                              #
  #--------------------------------------------------------#
  # Cell-Types:
  cellTypes = c("cd4","cd8")
  
  # Data Set Necessities:
  clust.start = 1
  clust.end = length(tmp.data)
  by.value = 15
  
  start.pts = seq(from = 1,to = clust.end,by = by.value)
  end.pts = c((start.pts[-1]-1),clust.end)
  
  cluster_output = list()
  for(m in 1:length(start.pts)){
    
    # Call Revised_Sim_MixCode_SI.R code
    curr.clust.opt = tmp.data[c(start.pt:end.pt)]
    curr.clust.out = STG.Update_Cluster.All(all_data=curr.clust.opt, cellTypes = cellTypes,
                                            optimType="nlminb", simple.Init=FALSE, initPts=c(0.5))
    
    cluster_output[[m]] = curr.clust.out
  }
  
  IsoDeconv_Output[[i]] = cluster_output
}

```


## Edit of Updated Process

Note: Once I'm confident the "Updated Process" steps above work as expected, I will modularize some steps (create some additional functions). Ideally, it would be nice to have just one "wrapper" function where all of the inputs go and one output.

The End
